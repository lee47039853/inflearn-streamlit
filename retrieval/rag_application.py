"""
RAG ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ ëª¨ë“ˆ
"""

import os
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv

from .config import Config
from .embedding_manager import EmbeddingManager
from .database_manager import DatabaseManager
from .conversation_history import ConversationHistory
from .enhanced_rag import EnhancedRAGSystem
from .user_interface import UserInterface
from .command_processor import CommandProcessor


class RAGApplication:
    """RAG ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.db_manager = DatabaseManager()
        self.conversation_history = ConversationHistory()
        self.enhanced_rag = None
        self.command_processor = None
    
    def initialize(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”"""
        load_dotenv()
        
        # Google API í‚¤ í™•ì¸
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì— GOOGLE_API_KEY=your_api_key_hereë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
            return False
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬
        has_existing_db = self.db_manager.check_existing_database()
        
        if has_existing_db:
            choice = UserInterface.get_user_choice(
                "ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ì˜µì…˜:",
                [
                    "ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì¬ì‚¬ìš© (ë¹ ë¦„)",
                    "ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ì²˜ìŒ ì‹¤í–‰)",
                    "ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±"
                ]
            )
            
            if choice == '3':
                self.db_manager.clear_database()
                has_existing_db = False
        else:
            print("ğŸ“„ ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        # ì„ë² ë”© ëª¨ë¸ ì„ íƒ
        embedding_choice = UserInterface.get_user_choice(
            "ğŸ“Š ì„ë² ë”© ëª¨ë¸ ì„ íƒ:",
            [
                "í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ (ko-sroberta-multitask) - ì¶”ì²œ",
                "Google Gemini ì„ë² ë”© (ê¸°ì¡´)"
            ]
        )
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        print("\nğŸ”§ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        embedding = EmbeddingManager.create_embedding(embedding_choice)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        database = self.db_manager.create_database(embedding)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬
        if has_existing_db and choice == '1':
            print("ğŸ“š ê¸°ì¡´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì‚¬ìš© ì¤‘...")
            try:
                collection_count = database._collection.count()
                print(f"âœ… ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {collection_count}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸  ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
                print("   ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                has_existing_db = False
        
        if not has_existing_db or choice == '2':
            document_list = self.db_manager.load_documents()
            database.add_documents(document_list)
            print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")
        
        # LLM ëª¨ë¸ ì´ˆê¸°í™”
        llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.9)
        
        # ì¿¼ë¦¬ ìµœì í™” ê¸°ëŠ¥ ì„ íƒ
        optimization_choice = UserInterface.get_user_choice(
            "ğŸ”§ ì¿¼ë¦¬ ìµœì í™” ê¸°ëŠ¥ ì„¤ì •:",
            [
                "ì¿¼ë¦¬ ìµœì í™” í™œì„±í™” (LLMì„ í†µí•œ ì§ˆë¬¸ ê°œì„ ) - ì¶”ì²œ",
                "ì¿¼ë¦¬ ìµœì í™” ë¹„í™œì„±í™” (ì›ë³¸ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©)"
            ]
        )
        
        use_optimization = (optimization_choice == '1')
        
        # í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("\nğŸ”§ í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self.enhanced_rag = EnhancedRAGSystem(database, llm, use_query_optimization=use_optimization)
        print("âœ… í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        if use_optimization:
            print("âœ… ì¿¼ë¦¬ ìµœì í™” ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("ğŸš« ì¿¼ë¦¬ ìµœì í™” ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ëª…ë ¹ì–´ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        self.command_processor = CommandProcessor(self.conversation_history, self.enhanced_rag)
        
        return True
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        if not self.initialize():
            print("âŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        print("\nğŸ¤– ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
        print("   (ì—¬ëŸ¬ ì¤„ ì…ë ¥ ê°€ëŠ¥: ê° ì¤„ ì…ë ¥ í›„ Enter, 'END'ë¡œ ì™„ë£Œ, 'CANCEL'ë¡œ ì·¨ì†Œ)")
        print("   (ì˜ˆ: ì œ 55ì¡°ì˜ ì¢…í•©ì†Œë“ ê³¼ì œí‘œì¤€ ê¸°ì¤€ìœ¼ë¡œ ê±°ì£¼ìì˜ ì—°ë´‰ì´ 5ì²œë§Œì› ì¸ ê²½ìš°")
        print("        í•´ë‹¹ ê±°ì£¼ìì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì¸ê°€ìš”?)")
        print("   (ì…ë ¥ ì¤‘ 'CLEAR'ë¡œ ë‚´ìš© ì§€ìš°ê¸°, 'CANCEL'ë¡œ ì…ë ¥ ì·¨ì†Œ)")
        print("   (ì…ë ¥ ì¤‘ íˆìŠ¤í† ë¦¬ ì œì–´: disable_history, enable_history, clear_history, reset_conversation, clear_and_disable)")
        print("   (ì¿¼ë¦¬ ìµœì í™” ì œì–´: toggle_optimization, optimization_status)")
        print("   (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥)")
        print("   (ëŒ€í™” íˆìŠ¤í† ë¦¬: show_history, clear_history, show_context)")
        print("   (íˆìŠ¤í† ë¦¬ ì œì–´: disable_history, enable_history, remove_last, remove_history:ë²ˆí˜¸, history_status)")
        print("   (ì™„ì „ ì´ˆê¸°í™”: reset_conversation, clear_and_disable)")
        print("-" * 50)
        
        while True:
            try:
                # ì—¬ëŸ¬ ì¤„ ì§ˆë¬¸ ì…ë ¥ ë°›ê¸°
                query = UserInterface.get_multiline_input()
                
                if not query:
                    continue
                
                # ì…ë ¥ëœ ì§ˆë¬¸ í™•ì¸
                query_lines = query.split()
                UserInterface.display_query_info(query, query_lines)
                
                # íˆìŠ¤í† ë¦¬ ìƒíƒœ í‘œì‹œ
                status = self.conversation_history.get_history_status()
                if status['enabled']:
                    print(f"ğŸ’¾ íˆìŠ¤í† ë¦¬ ìƒíƒœ: í™œì„±í™” (ì €ì¥ë¨: {status['count']}ê°œ)")
                else:
                    print(f"ğŸš« íˆìŠ¤í† ë¦¬ ìƒíƒœ: ë¹„í™œì„±í™” (ì €ì¥ë˜ì§€ ì•ŠìŒ)")
                print("-" * 40)
                
                # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í™•ì¸ ë° ì ìš©
                relevant_context = self.conversation_history.get_relevant_context(query)
                if relevant_context:
                    print(f"\nğŸ”„ ê´€ë ¨ ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë°œê²¬:")
                    print(f"  {relevant_context}")
                    print("-" * 50)
                
                print(f"\nğŸ¤– ì…ë ¥ëœ ì§ˆë¬¸: {query}")
                print("-" * 50)
                
                # ì¿¼ë¦¬ ê°œì„  ë° RAG ì²˜ë¦¬
                if self.enhanced_rag is None:
                    print("âŒ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    continue
                result = self.enhanced_rag.process_query_with_improvement(query)
                
                # ê²°ê³¼ ì¶”ì¶œ
                improved_query = result['improved_query']
                retrieved_docs_with_scores = result['retrieved_docs']
                retrieved_docs = [doc for doc, _ in retrieved_docs_with_scores]
                ai_response = result['response']
                
                # ìœ ì‚¬ë„ ì ìˆ˜ ë¶„ì„
                UserInterface.display_similarity_analysis(retrieved_docs_with_scores)
                
                # ì „ì²´ ë¬¸ì„œ ë‚´ìš© ì¶œë ¥
                UserInterface.display_documents(retrieved_docs_with_scores)
                
                # ìµœì¢… ì§ˆì˜ ë¡œê·¸ ì¶œë ¥
                UserInterface.display_query_log(result)
                
                # RAG ì²´ì¸ì— ì „ë‹¬ë˜ëŠ” ì •ë³´
                UserInterface.display_rag_info(query, improved_query, retrieved_docs, self.conversation_history.current_context)
                
                # AI ì‘ë‹µ ì¶œë ¥
                ai_message = {'result': ai_response}
                print("\n" + "=" * 50)
                print("âœ… ìµœì¢… ì‘ë‹µ:")
                print(ai_message['result'])
                print("=" * 50)
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— êµí™˜ ì¶”ê°€
                self.conversation_history.add_exchange(query, ai_message['result'], retrieved_docs_with_scores)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return
            except Exception as e:
                print(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("   ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                continue 